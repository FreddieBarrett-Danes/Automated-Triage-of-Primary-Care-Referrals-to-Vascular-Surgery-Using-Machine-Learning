{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e4de20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "\n",
    "# Reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed()\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbd2833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "texts = df['letter_text'].astype(str).tolist()\n",
    "labels_type = df['referal_type'].astype(str).tolist()\n",
    "labels_urgency = df['urgency'].astype(str).tolist()\n",
    "\n",
    "# Encode labels\n",
    "label_encoder_type = LabelEncoder()\n",
    "label_encoder_urgency = LabelEncoder()\n",
    "labels_type_enc = label_encoder_type.fit_transform(labels_type)\n",
    "labels_urgency_enc = label_encoder_urgency.fit_transform(labels_urgency)\n",
    "\n",
    "num_classes_type = len(label_encoder_type.classes_)\n",
    "num_classes_urgency = len(label_encoder_urgency.classes_)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train_type, y_test_type, y_train_urgency, y_test_urgency = train_test_split(\n",
    "    texts, labels_type_enc, labels_urgency_enc, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4c49c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Output BERT Model\n",
    "class MultiOutputBertModel(nn.Module):\n",
    "    def __init__(self, model_name, num_type_classes, num_urgency_classes):\n",
    "        super(MultiOutputBertModel, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "\n",
    "        self.type_classifier = nn.Linear(self.bert.config.hidden_size, num_type_classes)\n",
    "        self.urgency_classifier = nn.Linear(self.bert.config.hidden_size, num_urgency_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None,\n",
    "                type_labels=None, urgency_labels=None):\n",
    "        # Get BERT outputs\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "\n",
    "    \n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "\n",
    "        # Get logits for both tasks\n",
    "        type_logits = self.type_classifier(pooled_output)\n",
    "        urgency_logits = self.urgency_classifier(pooled_output)\n",
    "\n",
    "        total_loss = None\n",
    "        if type_labels is not None and urgency_labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            type_loss = loss_fct(type_logits, type_labels)\n",
    "            urgency_loss = loss_fct(urgency_logits, urgency_labels)\n",
    "            total_loss = type_loss + urgency_loss\n",
    "\n",
    "        return {\n",
    "            'loss': total_loss,\n",
    "            'type_logits': type_logits,\n",
    "            'urgency_logits': urgency_logits\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f3dbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Output Dataset Class\n",
    "class MultiOutputTextDataset(Dataset):\n",
    "    def __init__(self, texts, type_labels, urgency_labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.type_labels = type_labels\n",
    "        self.urgency_labels = urgency_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'type_labels': torch.tensor(self.type_labels[idx], dtype=torch.long),\n",
    "            'urgency_labels': torch.tensor(self.urgency_labels[idx], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67084578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Trainer for Multi-Output\n",
    "class MultiOutputTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs['loss']\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    def prediction_step(self, model, inputs, prediction_loss_fn, ignore_keys=None):\n",
    "        inputs = self._prepare_inputs(inputs)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs['loss']\n",
    "\n",
    "            # Get predictions for both tasks\n",
    "            type_preds = outputs['type_logits']\n",
    "            urgency_preds = outputs['urgency_logits']\n",
    "\n",
    "            # Stack predictions\n",
    "            predictions = [type_preds, urgency_preds]\n",
    "            # Get labels\n",
    "            type_labels = inputs.get('type_labels')\n",
    "            urgency_labels = inputs.get('urgency_labels')\n",
    "            labels = [type_labels, urgency_labels]\n",
    "\n",
    "        return (loss, predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6d985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_multi_output_model(model_name, train_dataset, eval_dataset, num_type_classes, num_urgency_classes, output_dir):\n",
    "    # Initialize tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = MultiOutputBertModel(model_name, num_type_classes, num_urgency_classes)\n",
    "\n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=15,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=32,\n",
    "        logging_dir=f\"{output_dir}/logs\",\n",
    "        report_to=\"none\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"no\",\n",
    "        load_best_model_at_end=False\n",
    "    )\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = MultiOutputTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    return trainer, model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742cdd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_multi_output_model(trainer, test_dataset, y_test_type, y_test_urgency,\n",
    "                               label_encoder_type, label_encoder_urgency, model_name=\"Multi-Output BERT\"):\n",
    "\n",
    "    # Get predictions\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "\n",
    "    # Extract predictions for both tasks\n",
    "    type_predictions = predictions.predictions[0]\n",
    "    urgency_predictions = predictions.predictions[1]\n",
    "\n",
    "    # Convert to numpy\n",
    "    if hasattr(type_predictions, 'cpu'):\n",
    "        type_predictions = type_predictions.cpu().numpy()\n",
    "    if hasattr(urgency_predictions, 'cpu'):\n",
    "        urgency_predictions = urgency_predictions.cpu().numpy()\n",
    "\n",
    "    # Get predicted classes\n",
    "    y_pred_type = np.argmax(type_predictions, axis=1)\n",
    "    y_pred_urgency = np.argmax(urgency_predictions, axis=1)\n",
    "\n",
    "    # Check class presence for both tasks\n",
    "    present_type_classes = np.unique(np.concatenate([np.unique(y_test_type), np.unique(y_pred_type)]))\n",
    "    present_urgency_classes = np.unique(np.concatenate([np.unique(y_test_urgency), np.unique(y_pred_urgency)]))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"{model_name.upper()} Performance\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Class analysis\n",
    "    print(f\"\\nClass presence analysis:\")\n",
    "    print(f\"Referral Type - Classes present: {len(present_type_classes)}/{len(label_encoder_type.classes_)}\")\n",
    "    print(f\"Urgency - Classes present: {len(present_urgency_classes)}/{len(label_encoder_urgency.classes_)}\")\n",
    "\n",
    "    # Get labels for present classes\n",
    "    present_type_names = [label_encoder_type.classes_[i] for i in present_type_classes]\n",
    "    present_urgency_names = [label_encoder_urgency.classes_[i] for i in present_urgency_classes]\n",
    "\n",
    "    # Classification reports with proper class handling\n",
    "    print(\"\\nClassification Report: Referral Type\")\n",
    "    print(classification_report(y_test_type, y_pred_type,\n",
    "                              labels=present_type_classes,\n",
    "                              target_names=present_type_names,\n",
    "                              zero_division=0))\n",
    "\n",
    "    print(\"\\nClassification Report: Urgency\")\n",
    "    print(classification_report(y_test_urgency, y_pred_urgency,\n",
    "                              labels=present_urgency_classes,\n",
    "                              target_names=present_urgency_names,\n",
    "                              zero_division=0))\n",
    "\n",
    "\n",
    "    # Confusion Matrices\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    fig.suptitle(f'{model_name} Performance Visualization', fontsize=16)\n",
    "\n",
    "    # Referral Type Confusion Matrix\n",
    "    cm_type = confusion_matrix(y_test_type, y_pred_type, labels=present_type_classes)\n",
    "    sns.heatmap(cm_type, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "                xticklabels=present_type_names,\n",
    "                yticklabels=present_type_names)\n",
    "    axes[0].set_title(\"Confusion Matrix: Referral Type\")\n",
    "    axes[0].set_xlabel(\"Predicted Label\")\n",
    "    axes[0].set_ylabel(\"True Label\")\n",
    "\n",
    "    # Urgency Confusion Matrix\n",
    "    cm_urgency = confusion_matrix(y_test_urgency, y_pred_urgency, labels=present_urgency_classes)\n",
    "    sns.heatmap(cm_urgency, annot=True, fmt='d', cmap='Reds', ax=axes[1],\n",
    "                xticklabels=present_urgency_names,\n",
    "                yticklabels=present_urgency_names)\n",
    "    axes[1].set_title(\"Confusion Matrix: Urgency\")\n",
    "    axes[1].set_xlabel(\"Predicted Label\")\n",
    "    axes[1].set_ylabel(\"True Label\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209ff4ed",
   "metadata": {},
   "source": [
    "# Full Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c821bd6d",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb69b32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "train_dataset = MultiOutputTextDataset(\n",
    "    X_train, y_train_type, y_train_urgency, tokenizer\n",
    ")\n",
    "\n",
    "test_dataset = MultiOutputTextDataset(\n",
    "    X_test, y_test_type, y_test_urgency, tokenizer\n",
    ")\n",
    "\n",
    "# Train the multi-output model\n",
    "trainer, model, tokenizer = train_multi_output_model(\n",
    "    model_name=\"bert-base-uncased\",\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    num_type_classes=num_classes_type,\n",
    "    num_urgency_classes=num_classes_urgency,\n",
    "    output_dir=\"./multi_output_bert\"\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_multi_output_model(\n",
    "    trainer, test_dataset, y_test_type, y_test_urgency,\n",
    "    label_encoder_type, label_encoder_urgency\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0667dcc7",
   "metadata": {},
   "source": [
    "## ClinicalBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696614b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokenizer for ClinicalBERT\n",
    "clinical_tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "# Create datasets\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "train_dataset = MultiOutputTextDataset(\n",
    "    X_train, y_train_type, y_train_urgency, tokenizer\n",
    ")\n",
    "\n",
    "test_dataset = MultiOutputTextDataset(\n",
    "    X_test, y_test_type, y_test_urgency, tokenizer\n",
    ")\n",
    "\n",
    "# Train the multi-output model\n",
    "trainer, model, tokenizer = train_multi_output_model(\n",
    "    model_name=\"emilyalsentzer/Bio_ClinicalBERT\",\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    num_type_classes=num_classes_type,\n",
    "    num_urgency_classes=num_classes_urgency,\n",
    "    output_dir=\"./multi_output_clinical_bert\"\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_multi_output_model(\n",
    "    trainer, test_dataset, y_test_type, y_test_urgency,\n",
    "    label_encoder_type, label_encoder_urgency\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c92c32f",
   "metadata": {},
   "source": [
    "## 5-Fold Cross Validation for Both Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba5f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({\n",
    "    'text': texts,\n",
    "    'referal_type': labels_type_enc,\n",
    "    'urgency': labels_urgency_enc\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "X = df[['text']]\n",
    "y_type = df['referal_type'].values\n",
    "y_urgency = df['urgency'].values\n",
    "\n",
    "# Determine number of classes\n",
    "num_type_classes = len(np.unique(y_type))\n",
    "num_urgency_classes = len(np.unique(y_urgency))\n",
    "\n",
    "print(f\"Number of type classes: {num_type_classes}\")\n",
    "print(f\"Number of urgency classes: {num_urgency_classes}\")\n",
    "print(f\"Data shape: {X.shape}\")\n",
    "\n",
    "# === Prepare Cross-Validation ===\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "bert_results = {\"f1_type\": [], \"acc_type\": [], \"f1_urgency\": [], \"acc_urgency\": []}\n",
    "clinical_results = {\"f1_type\": [], \"acc_type\": [], \"f1_urgency\": [], \"acc_urgency\": []}\n",
    "\n",
    "for model_name, result_dict in [(\"bert-base-uncased\", bert_results),\n",
    "                                 (\"emilyalsentzer/Bio_ClinicalBERT\", clinical_results)]:\n",
    "    print(f\"\\nRunning {model_name}\")\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"\\nFold {fold+1}\")\n",
    "\n",
    "        # Split data using proper indexing\n",
    "        X_train = X.iloc[train_idx].reset_index(drop=True)\n",
    "        X_val = X.iloc[val_idx].reset_index(drop=True)\n",
    "        y_train_type = y_type[train_idx]\n",
    "        y_train_urgency = y_urgency[train_idx]\n",
    "        y_val_type = y_type[val_idx]\n",
    "        y_val_urgency = y_urgency[val_idx]\n",
    "\n",
    "        # Create tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "        # Datasets\n",
    "        train_dataset = MultiOutputTextDataset(X_train['text'], y_train_type, y_train_urgency, tokenizer)\n",
    "        val_dataset = MultiOutputTextDataset(X_val['text'], y_val_type, y_val_urgency, tokenizer)\n",
    "\n",
    "        # Train\n",
    "        trainer, model, tokenizer = train_multi_output_model(\n",
    "            model_name=model_name,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset,\n",
    "            num_type_classes=num_type_classes,\n",
    "            num_urgency_classes=num_urgency_classes,\n",
    "            output_dir=f\"./{model_name.replace('/', '_')}_fold{fold+1}\"\n",
    "        )\n",
    "\n",
    "        # Predict\n",
    "        predictions = trainer.predict(val_dataset)\n",
    "        type_preds = predictions.predictions[0].argmax(axis=1)\n",
    "        urgency_preds = predictions.predictions[1].argmax(axis=1)\n",
    "\n",
    "        # Evaluate\n",
    "        result_dict[\"f1_type\"].append(f1_score(y_val_type, type_preds, average='macro'))\n",
    "        result_dict[\"acc_type\"].append(accuracy_score(y_val_type, type_preds))\n",
    "        result_dict[\"f1_urgency\"].append(f1_score(y_val_urgency, urgency_preds, average='macro'))\n",
    "        result_dict[\"acc_urgency\"].append(accuracy_score(y_val_urgency, urgency_preds))\n",
    "\n",
    "        print(f\"Fold {fold+1} Results:\")\n",
    "        print(f\"  Type F1: {result_dict['f1_type'][-1]:.4f}, Acc: {result_dict['acc_type'][-1]:.4f}\")\n",
    "        print(f\"  Urgency F1: {result_dict['f1_urgency'][-1]:.4f}, Acc: {result_dict['acc_urgency'][-1]:.4f}\")\n",
    "\n",
    "# Summary Table\n",
    "df_results = pd.DataFrame({\n",
    "    \"Fold\": [1, 2, 3, 4, 5],\n",
    "    \"BERT_F1_Type\": bert_results['f1_type'],\n",
    "    \"ClinicalBERT_F1_Type\": clinical_results['f1_type'],\n",
    "    \"BERT_F1_Urgency\": bert_results['f1_urgency'],\n",
    "    \"ClinicalBERT_F1_Urgency\": clinical_results['f1_urgency']\n",
    "})\n",
    "\n",
    "# Calculate means and standard deviations\n",
    "print(\"\\n Summary Statistics \")\n",
    "print(f\"BERT Type F1: {np.mean(bert_results['f1_type']):.4f} ± {np.std(bert_results['f1_type']):.4f}\")\n",
    "print(f\"ClinicalBERT Type F1: {np.mean(clinical_results['f1_type']):.4f} ± {np.std(clinical_results['f1_type']):.4f}\")\n",
    "print(f\"BERT Urgency F1: {np.mean(bert_results['f1_urgency']):.4f} ± {np.std(bert_results['f1_urgency']):.4f}\")\n",
    "print(f\"ClinicalBERT Urgency F1: {np.mean(clinical_results['f1_urgency']):.4f} ± {np.std(clinical_results['f1_urgency']):.4f}\")\n",
    "\n",
    "print(\"\\nDetailed Results:\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e70d98",
   "metadata": {},
   "source": [
    "# Vascular-Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88ce1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and filter out non-vascular\n",
    "df = pd.read_csv('data.csv')\n",
    "df = df[df['referal_type'] != 'non vascular']\n",
    "\n",
    "print(\"Referral types after filtering:\")\n",
    "print(df['referal_type'].value_counts())\n",
    "\n",
    "texts = df['letter_text'].astype(str).tolist()\n",
    "labels_type = df['referal_type'].astype(str).tolist()\n",
    "labels_urgency = df['urgency'].astype(str).tolist()\n",
    "\n",
    "# Encode labels\n",
    "label_encoder_type = LabelEncoder()\n",
    "label_encoder_urgency = LabelEncoder()\n",
    "labels_type_enc = label_encoder_type.fit_transform(labels_type)\n",
    "labels_urgency_enc = label_encoder_urgency.fit_transform(labels_urgency)\n",
    "\n",
    "num_classes_type = len(label_encoder_type.classes_)\n",
    "num_classes_urgency = len(label_encoder_urgency.classes_)\n",
    "\n",
    "print(f\"\\nNumber of referral type classes: {num_classes_type}\")\n",
    "print(f\"Referral type classes: {label_encoder_type.classes_}\")\n",
    "print(f\"Number of urgency classes: {num_classes_urgency}\")\n",
    "print(f\"Urgency classes: {label_encoder_urgency.classes_}\")\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train_type, y_test_type, y_train_urgency, y_test_urgency = train_test_split(\n",
    "    texts, labels_type_enc, labels_urgency_enc, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b6f404",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1151cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets for multi-output model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "train_dataset = MultiOutputTextDataset(\n",
    "    X_train, y_train_type, y_train_urgency, tokenizer\n",
    ")\n",
    "\n",
    "test_dataset = MultiOutputTextDataset(\n",
    "    X_test, y_test_type, y_test_urgency, tokenizer\n",
    ")\n",
    "\n",
    "\n",
    "trainer, model, tokenizer = train_multi_output_model(\n",
    "    model_name=\"bert-base-uncased\",\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    num_type_classes=num_classes_type,\n",
    "    num_urgency_classes=num_classes_urgency,\n",
    "    output_dir=\"./multi_output_bert_nonvascular\"\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_multi_output_model(\n",
    "    trainer, test_dataset, y_test_type, y_test_urgency,\n",
    "    label_encoder_type, label_encoder_urgency\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d298b0e",
   "metadata": {},
   "source": [
    "## ClinicalBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada068db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets for multi-output model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "train_dataset = MultiOutputTextDataset(\n",
    "    X_train, y_train_type, y_train_urgency, tokenizer\n",
    ")\n",
    "\n",
    "test_dataset = MultiOutputTextDataset(\n",
    "    X_test, y_test_type, y_test_urgency, tokenizer\n",
    ")\n",
    "\n",
    "\n",
    "trainer, model, tokenizer = train_multi_output_model(\n",
    "    model_name=\"emilyalsentzer/Bio_ClinicalBERT\",\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    num_type_classes=num_classes_type,\n",
    "    num_urgency_classes=num_classes_urgency,\n",
    "    output_dir=\"./multi_output_clinical_bert_nonvascular\"\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_multi_output_model(\n",
    "    trainer, test_dataset, y_test_type, y_test_urgency,\n",
    "    label_encoder_type, label_encoder_urgency\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419bd558",
   "metadata": {},
   "source": [
    "## 5-Fold Cross Validation for Both Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f737e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'text': texts,\n",
    "    'referal_type': labels_type_enc,\n",
    "    'urgency': labels_urgency_enc\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "X = df[['text']]\n",
    "y_type = df['referal_type'].values\n",
    "y_urgency = df['urgency'].values\n",
    "\n",
    "# Determine number of classes\n",
    "num_type_classes = len(np.unique(y_type))\n",
    "num_urgency_classes = len(np.unique(y_urgency))\n",
    "\n",
    "print(f\"Number of type classes: {num_type_classes}\")\n",
    "print(f\"Number of urgency classes: {num_urgency_classes}\")\n",
    "print(f\"Data shape: {X.shape}\")\n",
    "\n",
    "# Prepare Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "bert_results = {\"f1_type\": [], \"acc_type\": [], \"f1_urgency\": [], \"acc_urgency\": []}\n",
    "clinical_results = {\"f1_type\": [], \"acc_type\": [], \"f1_urgency\": [], \"acc_urgency\": []}\n",
    "\n",
    "for model_name, result_dict in [(\"bert-base-uncased\", bert_results),\n",
    "                                 (\"emilyalsentzer/Bio_ClinicalBERT\", clinical_results)]:\n",
    "    print(f\"\\nRunning {model_name}\")\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"\\nFold {fold+1}\")\n",
    "\n",
    "        # Split data using proper indexing\n",
    "        X_train = X.iloc[train_idx].reset_index(drop=True)\n",
    "        X_val = X.iloc[val_idx].reset_index(drop=True)\n",
    "        y_train_type = y_type[train_idx]\n",
    "        y_train_urgency = y_urgency[train_idx]\n",
    "        y_val_type = y_type[val_idx]\n",
    "        y_val_urgency = y_urgency[val_idx]\n",
    "\n",
    "        # Create tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "        # Datasets\n",
    "        train_dataset = MultiOutputTextDataset(X_train['text'], y_train_type, y_train_urgency, tokenizer)\n",
    "        val_dataset = MultiOutputTextDataset(X_val['text'], y_val_type, y_val_urgency, tokenizer)\n",
    "\n",
    "        # Train\n",
    "        trainer, model, tokenizer = train_multi_output_model(\n",
    "            model_name=model_name,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset,\n",
    "            num_type_classes=num_type_classes,\n",
    "            num_urgency_classes=num_urgency_classes,\n",
    "            output_dir=f\"./{model_name.replace('/', '_')}_fold{fold+1}\"\n",
    "        )\n",
    "\n",
    "        # Predict\n",
    "        predictions = trainer.predict(val_dataset)\n",
    "        type_preds = predictions.predictions[0].argmax(axis=1)\n",
    "        urgency_preds = predictions.predictions[1].argmax(axis=1)\n",
    "\n",
    "        # Evaluate\n",
    "        result_dict[\"f1_type\"].append(f1_score(y_val_type, type_preds, average='macro'))\n",
    "        result_dict[\"acc_type\"].append(accuracy_score(y_val_type, type_preds))\n",
    "        result_dict[\"f1_urgency\"].append(f1_score(y_val_urgency, urgency_preds, average='macro'))\n",
    "        result_dict[\"acc_urgency\"].append(accuracy_score(y_val_urgency, urgency_preds))\n",
    "\n",
    "        print(f\"Fold {fold+1} Results:\")\n",
    "        print(f\"  Type F1: {result_dict['f1_type'][-1]:.4f}, Acc: {result_dict['acc_type'][-1]:.4f}\")\n",
    "        print(f\"  Urgency F1: {result_dict['f1_urgency'][-1]:.4f}, Acc: {result_dict['acc_urgency'][-1]:.4f}\")\n",
    "\n",
    "\n",
    "# Summary Table\n",
    "df_results = pd.DataFrame({\n",
    "    \"Fold\": [1, 2, 3, 4, 5],\n",
    "    \"BERT_F1_Type\": bert_results['f1_type'],\n",
    "    \"ClinicalBERT_F1_Type\": clinical_results['f1_type'],\n",
    "    \"BERT_F1_Urgency\": bert_results['f1_urgency'],\n",
    "    \"ClinicalBERT_F1_Urgency\": clinical_results['f1_urgency']\n",
    "})\n",
    "\n",
    "# Calculate means and standard deviations\n",
    "print(\"\\nSummary Statistics\")\n",
    "print(f\"BERT Type F1: {np.mean(bert_results['f1_type']):.4f} ± {np.std(bert_results['f1_type']):.4f}\")\n",
    "print(f\"ClinicalBERT Type F1: {np.mean(clinical_results['f1_type']):.4f} ± {np.std(clinical_results['f1_type']):.4f}\")\n",
    "print(f\"BERT Urgency F1: {np.mean(bert_results['f1_urgency']):.4f} ± {np.std(bert_results['f1_urgency']):.4f}\")\n",
    "print(f\"ClinicalBERT Urgency F1: {np.mean(clinical_results['f1_urgency']):.4f} ± {np.std(clinical_results['f1_urgency']):.4f}\")\n",
    "\n",
    "print(\"\\nDetailed Results:\")\n",
    "print(df_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
